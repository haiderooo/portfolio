---
title: "Machine Learning: the science behind the buzzword."
excerpt_separator: "<!--more-->"
categories:
  - project1
tags:
  - experiments
  - tests
image: images/ML-Pcast-Banner-1.png
published: true
---

Take aways from a podcast episode that initiates you into the world of Machine learning and its everyday applications.
<!--more-->

Even before the AI boom, Machine Learning (ML) was gaining a lot of traction,
especially in discourse on social media algorithms. I am sure we have all tried 
and failed to wrap our heads around the science behind ML through jargon laden
explanations which require their own explanations, especially if you don’t have a 
computer science background. So, it was exciting when my professor in a digital humanities course 
assigned CS50 Podcast’s episode on the subject. I was not dissapointed after listening to it.


![a random image]({{site.baseurl}}images/ML-Pcast-Summary-1.webp)




**Introduction**


![a random image]({{site.baseurl}}images/ML-Pcast-Summary-2.webp)


This conversation between Harvard faculty computer scientists David J. Malan and Brian Yu is 
the most digestible, insightful and concise introduction to ML that I have come across so far. 
The tech terminology is illustrated through everyday application examples and the banter is great. 
So, I recommend you go have a listen by clicking [here](https://open.spotify.com/episode/2ppGzcN7KjeRRDGafyluDb?si=52824ea4ac5446f2&nd=1&dlsi=5583055a75164d3d) 
but if you prefer the written letter more, read along for my 
take aways from listening to the episode.


Post ChatGPT release, both ML and AI have become household terms. To start off, it is important to 
know the difference between the two. AI is the umbrella term. Whereas, ML is a subset of AI technologies. 
A lot of AI is built upon ML algorithms but some AI does not make use of ML.


From traffic lights to voice command processors like Siri, there is a dearth of ML technologies 
that we see emerging. Calling all of them ML does not give much insight. A fruitful categorization 
to understand the diversity of ML is through the relationship between humans and ML. 
In this respect, ML can be understood as reinforced, supervised and unsupervised.


**Reinforced ML**


![a random image]({{site.baseurl}}images/ML-Pcast-Summary-3.webp)


If you have played chess against the computer, you were beaten by a reinforced ML program. 
Reinforcement here is almost the same as it is in the case of training pets or educating children. 
In this case the rewards and penalties are achievement and non-achievement of the goal of winning 
for the computer. Each time someone beat the computer over the years, they taught it what tactics 
it needs to change to maximize winning. Each time it beat you cold, it learnt what it needs to keep doing. 
For all tactics and strategies it kept on accumulating data and optimizing best strategies.


**Supervised ML**


![a random image]({{site.baseurl}}images/ML-Pcast-Summary-4.jpg)


Then comes supervised ML, where we send off the program to explore after giving it the data and labels. 
One example of it, especially relevant to DH is that of Hand Written data Recognition or HTR. 
You might have heard of digitally deposited checks. To train the ML model for this purpose, 
you provide data of checks with amount numbers written by hand and you label the digits as numerals. 
Once trained on some data, the ML learns to classify the possible variations into numerals. 
Supervised ML models commonly deal with classification problems like this. 
We see applications of HTR in ipads, manuscript digitization/computation and so on. 
As good DH practitioners you might ask what about the fine-tuning that we do on HTR recognition? 
Don’t we use reinforcement? You would not be wrong. Reinforcement can be involved in supervised ML processes.


**Unsupervised ML**


![a random image]({{site.baseurl}}images/ML-Pcast-Summary-5.webp)


For a reasonable number of possible characters of an alphabet or numerals, you can, however, painstakingly assign labels. 
When it comes to more complex data, such as natural language processing, where you cannot possibly take account of all 
categories yourself, you use unsupervised ML. This is what Bezos and Buffet profit off. 
It is impossible for human teams to group consumers with slight differences in habits and behavior. 
So, you let the ML model to group consumers and behaviors itself. This is known as clustering. For natural language processing, 
you can take the example of open-ended voice command software like Siri and Alexa.


**Difference between ML and conventional programming**


![a random image]({{site.baseurl}}images/ML-Pcast-Summary-6.png)


Don’t get me wrong, even for reinforcement and unsupervised learning you wouldn’t be able to tell exactly how the model has 
arrived at the conclusions and predictions that it has. That is what separates ML from non-ML programming, whereby in the 
latter case you provide a set of instructions to execute tasks. For ML, the instructions are to learn to do tasks. 
So it makes sense to use ML only for cases beyond programming instructions from end to end such as using loops and statements. 
For example, in the case of LCD guided rear screens in cars, the technology may not be ML but a combination of 
distance-to-object sensitive sensors.


Speaking of cars, we have all seen the Tesla self-driving disaster tiktoks. 
For self-driving cars the models are definitely unsupervised. The technology is not there yet, but it is developing. 
It is the same for the Siris and the Google Translates of the world.


**Looking ahead**


![a random image]({{site.baseurl}}images/ML-Pcast-Summary-7.webp)


In terms of the tech these are interesting times. The explosion of AI and ML technologies have been enabled by the availability 
of large amounts of digital data, data storage capacities and computing power as well as ever improving ML algorithms. 
At the same time, these are also dangerous times. The same ML models are also being used by the likes of Palantir and other 
such surveillance, bordering and military tech programs, making it easy for governments and corporations to breach privacies, 
influence us, police us and impose violence through cold computer driven decisions. In any case, it is indispensable now to 
understand these technologies as much as social and political theory in order to build defensive and revolutionary strategies.


Click [here](https://open.spotify.com/episode/2ppGzcN7KjeRRDGafyluDb?si=52824ea4ac5446f2&nd=1&dlsi=5583055a75164d3d) to listen to CS50 Podcast Episode 06: Machine Learning hosted by David J. Malan and Brian Yu.
